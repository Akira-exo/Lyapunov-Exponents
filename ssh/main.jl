
#----------------------------------------INTRODUCTION--------------------------------------------------------------------
# main.jl takes no arguments from the terminal
#ARGS is the array that stores the arguments passed to the julia program (as STRINGs, hence they need to be parsed as Int)
#-------------------------------------------------------------------------------------------------------------


#----------------------------------------IMPORT REQUIRED LIBRARIES----------------------------------------------------------------
# (TIP: REMEMBER TO ADD ALL THESE LIBRARIES WHICH ARE BEING IMPORTED TO A NEW ENVIRONMENT AND GET THE PROJECT.TOML FILE !!!)

using Distributed, ClusterManagers,DelimitedFiles,LinearAlgebra
@everywhere pushfirst!(Base.DEPOT_PATH, "/tmp/test.cache") #important!
@everywhere using Dates    
@everywhere using LinearAlgebra
@everywhere using DelimitedFiles
@everywhere using Statistics
@everywhere using Distributions

#---------------------------------IMPORT REQUIRED FUNCTIONALITY-----------------------------------------------------------------

include("FindLyapunov.jl") #from the project directory where main.jl is
#include("System_parameters.jl")  #from the project directory where main.jl is
include(string(dir_name,"/System_parameters.jl")) # from the I/O directory

#-----------------------------------------DEFINE FUNCTIONS--------------------------------------------------------------------------------------

#=
Function to distribute 'nprocs' jobs to 'machines'
=#

function distribute_jobs(nprocs, machines)
j=1
for i in 1:nprocs
   if(j>length(machines)) 
     j=1
    end
   params = (exename=`nice -19 /vol/thp/share/julia-1.0.0-x86_64/bin/julia `, dir= dir_name )
   addprocs([(machines[j], 1)]; params...)
   j=j+1
 end

end


#=
Function to map each job information to its respective machine
=#

function map_jobs(nprocs,m_list,W_list)

	  map= zeros(nprocs,4)
	
          count=1
          for m in m_list
             for W in W_list
                 map[count,1]= count+1 #id of the worker
	     	 map[count,2]= fetch(@spawnat count+1  getpid())
	     	 map[count,3]= m # corresponding m
	     	 map[count,4]= W # corresponding W
	      	 count+=1
              end
          end
          
          filename=string(pwd(),"/TaskID(#,pid,m,W).txt")
     end
    
     writedlm(filename,map)
     return(map)

end

#=
Function to call worker 'i' to perform the job with jobID 'i' each job = one (m,W)
=#

@everywhere function perform_job(m::Float64,W::Float64,Ly_list::Array{Int64},jobID::Int64,dir_name::String)

        #NOTE: WORKER'S ID = myid()

        println("starting my job $(jobID) at $(gethostname()) on time $(now()) ")

        #SYSTEM PARAMETERS: 
        J_x,J_y,M,系,p,scale,q = get_SystemParameters()
        for Ly in Ly_list
		= assign_M(M,J_y,Ly,p)
		,,,t=assign_J(J_x,Ly)
        	Nx=scale*Ly
		位_list,Q_prev=calc_LyapunovList(,,,t,系,Ly,Nx,W,q)
	        filename = string(dir_name,"/位_list/位(m,W,Ly)=(",jobID,",",Ly,") )
                writedlm(filename,位_list, ", ")
                filename = string(dir_name,"/Q_prev/Q(m,W,Ly)=(",jobID,",",Ly,") )
                writedlm(filename,Q_prev, ", ")
	end
        println("finishing my job $(jobID) at $(gethostname()) on time $(now()) ")


end
#-------------------------------------------READING INPUTS------------------------------------------------------------------------



dir_name= string(pwd())  #I/O directory= current working directory

println(string("THE INPUT/OUTPUT directory is ",dir_name))

m_list = readdlm(string(dir_name,"/m_list.txt"),' ')
W_list = readdlm(string(dir_name,"/W_list.txt"),' ')
Ly_list = Int64.(readdlm(string(dir_name,"/Ly_list.txt"),' '))


#---------------------------------------IMPORT CLUSTER STATUS-----------------------------------------------------------------

machines=readdlm("/home/anegi/complist/available_complist.txt",' ') #list of available computers on the THP NETWORK by running cinit.sh
nprocs= length(m_list)*length(W_list) # one (m,W) per worker
println("starting ", nprocs, " processes...")
println("one (m,W) per worker")
println("on THP CLUSTER :O!!")

#------------------------------------- SET UP WORKERS/PROCESSES--------------------------------------------------
distribute_jobs(nprocs, machines)
println("Started ",nworkers()," workers\n")
println("Done.\n")

#SSH Manager is automatically called when you call addprocs() with an array

#--------------------------------------MAP tasks to workers-----------------------------------------------------------------------
map= map_jobs(nprocs,m_list,W_list)
#-----------------------------------------------------------------------------------------------------------------------------------------------------


#--------------------------------------DO TASK!!!!!!------------------------------------------------------------------------------

#creating directories for outputs
mkdir(string(dir_name,"/位_list"))
mkdir(string(dir_name,"/Q_prev"))



@sync for i in workers() 
      
      #host, pid = fetch(@spawnat i (gethostname(), getpid()))
      #println("I'm worker $i running on host $host with pid $pid at time $(now())")
      m=map[i-1,3]
      W=map[i-1,4]
      # println("My (m,W) is (",m,", ",W,")")

      @async @spawnat i perform_job(m,W,Ly_list,i,dir_name) 

end
println("JOB COMPLETE! Congratulations!!")


#--------------------------remove workers-------------------------
for i in workers()
        rmprocs(i)
end

#------------------------------------------------------------------
